{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a10881",
   "metadata": {},
   "source": [
    "## Task I\n",
    "\n",
    "* run the query belllow\n",
    "  * in the query we want to aggregate number of questions for each user and then join it with the users dataset\n",
    "* see the query plan and find out what is not optimal\n",
    "* try to optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf386549",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Optimize IV')\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2579a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = spark.table('questionsA')\n",
    "\n",
    "users = spark.table('usersB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053eb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.autoBroadcastJoinThreshold', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_questions = (\n",
    "    questions\n",
    "    .groupBy('user_id')\n",
    "    .agg(\n",
    "        count('*').alias('n')\n",
    "    )\n",
    ")\n",
    "\n",
    "(\n",
    "    users.join(num_questions, 'user_id')\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .format('noop')\n",
    "    .save()  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c0398",
   "metadata": {},
   "source": [
    "See the query plan\n",
    "\n",
    "* What is suboptimal?\n",
    "* What can we do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737b992",
   "metadata": {},
   "source": [
    "The users table is bucketed by `user_id`, so we should be able to join with the questions without shuffle in the users branch. That is indeed happening, but we have two shuffles in the other branch, but one shuffle should be sufficient for the aggregation, the join shouldn't require another shuffle.\n",
    "\n",
    "The problem is that the joining column `user_id` has a different data type in both tables, it is `long` in users, but `int` in questions, which you can see when calling `printSchema()`. We can cast the type to be long before the aggregation, so spark doesn't need to re-shuffle the data again just because of the cast before the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc55c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_questions = (\n",
    "    questions\n",
    "    .withColumn('user_id', col('user_id').cast('long'))\n",
    "    .groupBy('user_id')\n",
    "    .agg(\n",
    "        count('*').alias('n')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dabc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    users.join(num_questions, 'user_id')\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .format('noop')\n",
    "    .save()  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3615a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark Delta Python 3.10.1",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
