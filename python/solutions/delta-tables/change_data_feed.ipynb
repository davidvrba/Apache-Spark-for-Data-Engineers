{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9e3d15-a4fb-461f-a800-1a01319ffe32",
   "metadata": {},
   "source": [
    "# Change Data Feed\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "* recreate the Delta table in the metastore from the data which is in the location\n",
    "* enable the Change Data Feed (CDF) feature on a Delta table\n",
    "* delete a record and query the CDF\n",
    "* append the record back using the CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dfd0b2-4e8d-4ff2-b729-c8b9dd387391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from delta.tables import DeltaTable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf69771-1b19-4588-98f9-116a3aebbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('delta-II')\n",
    "    .config('spark.jars.packages', 'io.delta:delta-spark_2.12:3.2.1')\n",
    "    .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension')\n",
    "    .config('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542884ac-b59d-4c73-8e1c-197c409c7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "users_base_path = os.path.join(project_path, 'data/users_base')\n",
    "users_increment_path = os.path.join(project_path, 'data/users_increment')\n",
    "accounts_output_path = os.path.join(project_path, 'output/accounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa403757-f24d-4a1e-85bc-317a53966eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('drop table if exists accounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948f6f3-4e0d-458e-9cfa-994304c2440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE accounts\n",
    "    USING DELTA\n",
    "    LOCATION '{accounts_output_path}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd5537-2ecd-4ca5-8064-c35981fc2df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b082b31-bd5c-4a70-a240-d417a7f7c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on the CDF feature:\n",
    "\n",
    "spark.sql('ALTER TABLE accounts SET TBLPROPERTIES (delta.enableChangeDataFeed = true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d7dc3-8133-46f5-a3b1-651ab53977df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the table history:\n",
    "\n",
    "spark.sql('describe history accounts').select('version', 'timestamp', 'operation').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff09b0-5c0b-4a39-8094-0fe94eb39356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the table properties:\n",
    "\n",
    "spark.sql('show tblproperties accounts').show(truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fa42ad-1cf1-4fb9-ac17-6afe589a239f",
   "metadata": {},
   "source": [
    "## Query the CDF \n",
    "\n",
    "* see the [docs](https://docs.delta.io/latest/delta-change-data-feed.html)\n",
    "* for the `startingVersion` option use the version when it was turned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f2ce5-336a-4ad3-bde9-a3ea9d582b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n",
    "(\n",
    "    spark.read\n",
    "    .format('delta')\n",
    "    .option('readChangeFeed', 'true')\n",
    "    .option('startingVersion', 7)\n",
    "    .table('accounts')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f6d56-931c-4be7-95d7-59a0832b682d",
   "metadata": {},
   "source": [
    "## Delete a row and then add it back using the CDF\n",
    "\n",
    "* from the accounts table delete the row whee user_id = 79\n",
    "* query the CDF again (you shoud see the change that happened)\n",
    "* filter for the delete _change_type\n",
    "* drop the additional columns\n",
    "* append the row back to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da506b-104d-4c51-ab85-944f3f40d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the row where user_id = 79:\n",
    "\n",
    "DeltaTable.forName(spark, 'accounts').delete(col('user_id') == 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c64359-bf76-46d7-b9b7-2d09fc4ada5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the CDF:\n",
    "\n",
    "(\n",
    "    spark.read\n",
    "    .format('delta')\n",
    "    .option('readChangeFeed', 'true')\n",
    "    .option('startingVersion', 7)\n",
    "    .table('accounts')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5fc5d-77c1-47d0-b11c-efc7a434b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the row back:\n",
    "\n",
    "(\n",
    "    spark.read\n",
    "    .format('delta')\n",
    "    .option('readChangeFeed', 'true')\n",
    "    .option('startingVersion', 7)\n",
    "    .table('accounts')\n",
    "    .filter(col('_change_type') == 'delete')\n",
    "    .drop('_change_type', '_commit_version', '_commit_timestamp')\n",
    "    .write\n",
    "    .mode('append')\n",
    "    .format('delta')\n",
    "    .option('path', accounts_output_path)\n",
    "    .saveAsTable('accounts')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce159b13-0f37-434f-9ba1-2ca1d90984e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the history of the table:\n",
    "\n",
    "spark.sql('describe history accounts').select('version', 'timestamp', 'operation').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bec510-22fa-417f-a35c-ad380a7a82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the CDF again and see the append:\n",
    "\n",
    "(\n",
    "    spark.read\n",
    "    .format('delta')\n",
    "    .option('readChangeFeed', 'true')\n",
    "    .option('startingVersion', 7)\n",
    "    .table('accounts')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a07685-47c8-4f59-b0bf-9589c16bc9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
